{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#GPU使用可能確認\n",
    "print(torch.cuda.is_available())\n",
    "#使用できるデバイス数確認\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 31 11:50:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   0  NVIDIA GeForce ...  On   | 00000000:81:00.0  On |                  N/A |\n",
      "| 35%   45C    P8    39W / 350W |    308MiB / 24576MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 30%   42C    P8    19W / 350W |     13MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2157250      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A   2815414      G   /usr/lib/xorg/Xorg                150MiB |\n",
      "|    0   N/A  N/A   2987369      G   /usr/bin/gnome-shell               84MiB |\n",
      "|    1   N/A  N/A   2157250      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   2815414      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (4.30.2)\n",
      "Requirement already satisfied: filelock in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: mojimoji in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (0.0.12)\n",
      "Requirement already satisfied: pyknp in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (0.6.1)\n",
      "Requirement already satisfied: six in /home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages (from pyknp) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install mojimoji\n",
    "! pip install pyknp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import mojimoji\n",
    "import pandas as pd\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "from pyknp import Juman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###　ターミナルで形態素解析juman++のインストール\n",
    "https://qiita.com/Gushi_maru/items/ee434b5bc9f020c8feb6\n",
    "・jumanpp-2.0.0-rc3 download\n",
    "wget https://github.com/ku-nlp/jumanpp/releases/download/v2.0.0-rc3/jumanpp-2.0.0-rc3.tar.xz\n",
    "・unzip a file\n",
    "tar xvf jumanpp-2.0.0-rc3.tar.xz\n",
    "・コンパイラのインストール\n",
    "sudo apt update -y\n",
    "sudo apt upgrade -y\n",
    "sudo apt install build-essential -y\n",
    "・cmakeインストール\n",
    "sudo apt install cmake -y\n",
    "・コンパイラ用フォルダ作成\n",
    "cd [jumanディレクトリのパスの指定]\n",
    "mkdir build\n",
    "・juman++コンパイル\n",
    "cd [buildのパス指定]\n",
    "cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local\n",
    "make\n",
    "・コンパイル完了したらインストール開始\n",
    "sudo make install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "すもも すもも すもも 名詞 6 普通名詞 1 * 0 * 0 \"自動獲得:テキスト\"\n",
      "@ すもも すもも すもも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:酸桃/すもも 自動獲得:EN_Wiktionary\"\n",
      "も も も 助詞 9 副助詞 2 * 0 * 0 NIL\n",
      "もも もも もも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:桃/もも ドメイン:料理・食事 カテゴリ:植物;人工物-食べ物 漢字読み:訓\"\n",
      "@ もも もも もも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:股/もも カテゴリ:動物-部位\"\n",
      "も も も 助詞 9 副助詞 2 * 0 * 0 NIL\n",
      "もも もも もも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:桃/もも ドメイン:料理・食事 カテゴリ:植物;人工物-食べ物 漢字読み:訓\"\n",
      "@ もも もも もも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:股/もも カテゴリ:動物-部位\"\n",
      "も も も 助詞 9 副助詞 2 * 0 * 0 NIL\n",
      "もも もも もも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:桃/もも ドメイン:料理・食事 カテゴリ:植物;人工物-食べ物 漢字読み:訓\"\n",
      "@ もも もも もも 名詞 6 普通名詞 1 * 0 * 0 \"代表表記:股/もも カテゴリ:動物-部位\"\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "#juman++動作確認\n",
    "! echo すももももももももももも | jumanpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jiuman++のバージョン確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juman++ Version: 2.0.0-rc3 / Dictionary: 20190731-356e143 / LM: K:20190430-7d143fb L:20181122-b409be68 F:20171214-9d125cb\n"
     ]
    }
   ],
   "source": [
    "! jumanpp -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然言語処理のBERTについて学習中です。\n",
      "['自然', '言語', '処理', 'の', 'BERT', 'に', 'ついて', '学習', '中', 'です', '。']\n"
     ]
    }
   ],
   "source": [
    "# JUMANの動作確認\n",
    "from pyknp import Juman\n",
    "text = \"自然言語処理のBERTについて学習中です。\"\n",
    "juman = Juman()\n",
    "result =juman.analysis(text)\n",
    "result = [mrph.midasi for mrph in result.mrph_list()]\n",
    "print(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ダウンロードしたモデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nvocab_file = \"/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/deberta_models/vocab.txt\"\\nconfig_file = \"/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/deberta_models/config.json\"\\nmodel_file = \"/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/deberta_models/pytorch_model.bin\"\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "vocab_file = \"/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/deberta_models/vocab.txt\"\n",
    "config_file = \"/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/deberta_models/config.json\"\n",
    "model_file = \"/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/deberta_models/pytorch_model.bin\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 京都大学が公開している日本語Debertaモデル\n",
    "https://huggingface.co/ku-nlp/deberta-v2-base-japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ku-nlp/deberta-v2-base-japanese were not used when initializing DebertaV2Model: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ku-nlp/deberta-v2-base-japanese\")\n",
    "model = AutoModel.from_pretrained(\"ku-nlp/deberta-v2-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###bert_tokenizer = BertTokenizer(vocab_file, do_lower_case=False, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyknp import Juman\n",
    "\n",
    "class JumanTokenizer():\n",
    "    def __init__(self):\n",
    "        self.juman = Juman()\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        result = self.juman.analysis(text)\n",
    "        return [mrph.midasi for mrph in result.mrph_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "juman_tokenizer = JumanTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "    \n",
    "def preprocessing_text(text):\n",
    "       \n",
    "        text = mojimoji.han_to_zen(text) \n",
    "        \n",
    "        text = re.sub(r'[0-9 ０-９]+', '0', text)  \n",
    "\n",
    "        text = re.sub('\\r', '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "\n",
    "        text = text.replace(\"、\", \" \")\n",
    "        text = text.replace(\"。\", \" \")\n",
    "        \n",
    "        for p in string.punctuation:\n",
    "            if (p == \".\") or (p == \",\"):\n",
    "                continue\n",
    "            else:\n",
    "                text = text.replace(p, \" \")\n",
    "            return text\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "        text = preprocessing_text(text)\n",
    "        tokens = juman_tokenizer.tokenize(text)\n",
    "        tokens = tokenizer.tokenize(\" \".join(tokens))\n",
    "        ids = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + tokens+ [\"[SEP]\"])\n",
    "        return ids\n",
    "\n",
    "def preprocessing_sentences(text):\n",
    "        for i in range(len(text)):\n",
    "            text[i] = preprocessing_text(text[i])\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成したデータの読み込み\n",
    "df_train = pd.read_csv(\"/home/sakulab/workspace/yaguchi/research/Master/data/意見データ(5分割交差検証用)/train_data(5).csv\", header=0)\n",
    "#df_train = df_train.dropna(how='any') # nanのところは落とす（欠損値の削除）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (7000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>ピューロランド 関係 ない けど 面白い 漫画 見つけ た よ !! 彼氏 、 旦那 の 愚...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>すべては夢見ることから始まる。\\n\\n【ウォルト・ディズニー】＜ＵＲＬ＞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>眠く て 、 洗面 所 ( 特に 入ら ない か なー と 「 テレビ を 操作 し て 着...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>ピューロランド落選していく？</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>ひな ちと ユニバ だっ た ??? かわいい 赤ずきん を 引き連れ て 狼 し て まし...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>今年はサンリオピューロランドに行く？</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>今月 は あと 2回 撮影 の 予定 が あっ て 、 来月 は たくさん ヾ ( ・ ω ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>おととい の マツコの知らない世界 見 忘れ た から GYAO で 見直せ ば いい か ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>なんとディズニーデラックスでは月額７００円（初月無料）でアイアンマン２？ＩＷまで（ホームカミ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>みんな で ユニバ き て ほしい な ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1909  ピューロランド 関係 ない けど 面白い 漫画 見つけ た よ !! 彼氏 、 旦那 の 愚...      0\n",
       "4327               すべては夢見ることから始まる。\\n\\n【ウォルト・ディズニー】＜ＵＲＬ＞      0\n",
       "6869  眠く て 、 洗面 所 ( 特に 入ら ない か なー と 「 テレビ を 操作 し て 着...      0\n",
       "6139                                     ピューロランド落選していく？      0\n",
       "3643  ひな ちと ユニバ だっ た ??? かわいい 赤ずきん を 引き連れ て 狼 し て まし...      0\n",
       "2390                                 今年はサンリオピューロランドに行く？      1\n",
       "5098  今月 は あと 2回 撮影 の 予定 が あっ て 、 来月 は たくさん ヾ ( ・ ω ...      0\n",
       "1842  おととい の マツコの知らない世界 見 忘れ た から GYAO で 見直せ ば いい か ...      0\n",
       "2222  なんとディズニーデラックスでは月額７００円（初月無料）でアイアンマン２？ＩＷまで（ホームカミ...      0\n",
       "3811                              みんな で ユニバ き て ほしい な ?      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# データの確認\n",
    "print(f'データサイズ： {df_train.shape}')\n",
    "display(df_train.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成したデータの読み込み\n",
    "df_test = pd.read_csv(\"/home/sakulab/workspace/yaguchi/research/Master/data/意見データ(5分割交差検証用)/test_data(5).csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (1998, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1104 ホラナイピエロパタパタ くん と オレンテ くん が ジャンプ し て 遊ん でる...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>モンスターズインク面白かった、明日ユニバーシティみるー</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>続き 日本 の ハロウィン どうにか なら ない の か な ... 津野 さん の アカウ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>ディズニーキャラ以外で死ぬまでにしたい（着たい）コスプレ\\n・メイド（キャンディフルーツ）\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>大阪 の 即売会 に 参加 し て 1日 早く 入っ て 同人 仲間 と ユニバ で 遊ん ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>イベント 主催 者 から コンラッド NY の ツイン を 無料 で 1部 屋 与え られ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>ダウンロード 遅 すぎ て 生き てけない から 今日 は 寝よ か な 。 うん 明日 ユ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>今更 ながら ユニバイベー なみ さん に やっ っと 会え た ! あ きは に ひっ さ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>「 私たち は 前進 を 続け 、 新しい 扉 を 開き 、 新た な こと を なし 遂げ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>11 . 79 修学旅行 ・ 広島 … 写真 は デジカメ で ? ホテル 綺麗 だっ た ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1227  1104 ホラナイピエロパタパタ くん と オレンテ くん が ジャンプ し て 遊ん でる...      0\n",
       "339                         モンスターズインク面白かった、明日ユニバーシティみるー      0\n",
       "1512  続き 日本 の ハロウィン どうにか なら ない の か な ... 津野 さん の アカウ...      1\n",
       "352   ディズニーキャラ以外で死ぬまでにしたい（着たい）コスプレ\\n・メイド（キャンディフルーツ）\\...      0\n",
       "736   大阪 の 即売会 に 参加 し て 1日 早く 入っ て 同人 仲間 と ユニバ で 遊ん ...      0\n",
       "1699  イベント 主催 者 から コンラッド NY の ツイン を 無料 で 1部 屋 与え られ ...      0\n",
       "1175  ダウンロード 遅 すぎ て 生き てけない から 今日 は 寝よ か な 。 うん 明日 ユ...      0\n",
       "1221  今更 ながら ユニバイベー なみ さん に やっ っと 会え た ! あ きは に ひっ さ...      1\n",
       "1505  「 私たち は 前進 を 続け 、 新しい 扉 を 開き 、 新た な こと を なし 遂げ...      0\n",
       "1155  11 . 79 修学旅行 ・ 広島 … 写真 は デジカメ で ? ホテル 綺麗 だっ た ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'データサイズ： {df_test.shape}')\n",
    "display(df_test.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作成したデータの読み込み\n",
    "df_val = pd.read_csv(\"/home/sakulab/workspace/yaguchi/research/Master/data/意見データ(5分割交差検証用)/val_data(5).csv\",header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データサイズ： (996, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>前 お 店 で ディズニー の バッグ 持っ て 精算 待ち し て たら 、 店 の 女の...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>【 AM 新 景品 情報 】 # ディズニー の # ダンボ より 寝そべり # ぬいぐるみ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>スパイダーマンザ・ライド の キュー ライン 2 F は ヒーローヴィラン の 説明 欄 が...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>がんばっ て 今 まで の お つかれ ディズニー し て こよ ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>撮影 納め し たく ない けど 、 今日 ダンス を 撮影 しよ う と 思っ て 調べ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>ディズニー の キャラ が 苦手 っていう 致命 的 な 欠点 が ある</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>特別支援教育 って 本質的 に は 個人 の 学び の 保障 な はず な のに 、 今 な...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ピューロランド楽しんできました！\\n\\n私の大好きなビリーブ衣装のキティちゃんとダニエルくん...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>リッツカールトンやシェラトンでＶＩＰサービスを受けることができる「ＳＰＧアメックスカード」\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>鉾田の詐欺ハウステンボスわろた</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "319  前 お 店 で ディズニー の バッグ 持っ て 精算 待ち し て たら 、 店 の 女の...      1\n",
       "510  【 AM 新 景品 情報 】 # ディズニー の # ダンボ より 寝そべり # ぬいぐるみ...      1\n",
       "788  スパイダーマンザ・ライド の キュー ライン 2 F は ヒーローヴィラン の 説明 欄 が...      0\n",
       "538                 がんばっ て 今 まで の お つかれ ディズニー し て こよ ?      0\n",
       "635  撮影 納め し たく ない けど 、 今日 ダンス を 撮影 しよ う と 思っ て 調べ ...      0\n",
       "285               ディズニー の キャラ が 苦手 っていう 致命 的 な 欠点 が ある      0\n",
       "583  特別支援教育 って 本質的 に は 個人 の 学び の 保障 な はず な のに 、 今 な...      0\n",
       "102  ピューロランド楽しんできました！\\n\\n私の大好きなビリーブ衣装のキティちゃんとダニエルくん...      1\n",
       "30   リッツカールトンやシェラトンでＶＩＰサービスを受けることができる「ＳＰＧアメックスカード」\\...      0\n",
       "220                                    鉾田の詐欺ハウステンボスわろた      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'データサイズ： {df_val.shape}')\n",
    "display(df_val.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  え 、 ピューロランド 行き たい 。 。 。 誰か 連れ て っ て ← 絶対 SKY ー HI 可愛い やん 。 いや 、 カッコイイ パターン も あり ?\n",
      "Tokenized:  ['え', '\\u3000', '\\u3000', '\\u3000', 'ピュー', 'ロランド', '\\u3000', '行き', '\\u3000', 'たい', '\\u3000', '\\u3000', '\\u3000', '\\u3000', '\\u3000', '\\u3000', '\\u3000', '誰', 'か', '\\u3000', '連れ', '\\u3000', 'て', '\\u3000っ', '\\u3000', 'て', '\\u3000', '←', '\\u3000', '絶対', '\\u3000', 'ＳＫＹ', '\\u3000', 'ー', '\\u3000', 'ＨＩ', '\\u3000', '可愛い', '\\u3000', 'やん', '\\u3000', '\\u3000', '\\u3000', 'いや', '\\u3000', '\\u3000', '\\u3000', 'カッコイイ', '\\u3000', 'パターン', '\\u3000', 'も', '\\u3000', 'あり', '\\u3000', '？']\n",
      "Token IDs:  [1, 2654, 334, 334, 334, 4255, 1552, 2459, 334, 1459, 334, 371, 334, 334, 334, 334, 334, 334, 334, 1122, 294, 334, 6629, 334, 1872, 334, 1138, 334, 1872, 334, 16433, 334, 2372, 334, 475, 17490, 334, 2994, 334, 270, 14846, 334, 4820, 334, 17171, 334, 334, 334, 5792, 334, 334, 334, 19456, 895, 895, 334, 4333, 334, 276, 334, 317, 334, 354, 2]\n"
     ]
    }
   ],
   "source": [
    "# モデルに飲ませるデータと、ラベルを準備\n",
    "text_train = df_train.text.values\n",
    "labels_train = df_train.label.values\n",
    "\n",
    "\n",
    "## 確認\n",
    "print(' Original: ', text_train[0])\n",
    "print('Tokenized: ', juman_tokenizer.tokenize(preprocessing_text(text_train[0])))\n",
    "print('Token IDs: ', tokenizer_with_preprocessing(text_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  そういえば大阪のウンタラではＵＳＪのウンタラをウンタラするそうですね\n",
      "なるほどこの世界はなろう小説でしたか\n",
      "Tokenized:  ['そう', 'いえば', '大阪', 'の', 'ウンタラ', 'で', 'は', 'ＵＳＪ', 'の', 'ウンタラ', 'を', 'ウンタラ', 'する', 'そうです', 'ね', 'なるほど', 'この', '世界', 'は', 'なろう', '小説', 'でした', 'か']\n",
      "Token IDs:  [1, 849, 3551, 648, 262, 13561, 16889, 269, 266, 7970, 1667, 262, 13561, 16889, 265, 13561, 16889, 279, 1252, 383, 17910, 341, 427, 266, 11473, 1603, 588, 294, 2]\n"
     ]
    }
   ],
   "source": [
    "# モデルに飲ませるデータと、ラベルを準備\n",
    "text_val = df_val.text.values\n",
    "labels_val = df_val.label.values\n",
    "\n",
    "## 確認\n",
    "print(' Original: ', text_val[0])\n",
    "print('Tokenized: ', juman_tokenizer.tokenize(preprocessing_text(text_val[0])))\n",
    "print('Token IDs: ', tokenizer_with_preprocessing(text_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  レゴランドの向いにホテルが立ってるんですよー\n",
      "私も今日、初めて行きました；；\n",
      "レストランはビュッフェタイプでした。\n",
      "他にもバーとかありましたよ？\n",
      "少々お高いですが、わりと楽しめました！\n",
      "Tokenized:  ['レゴ', 'ランド', 'の', '向い', 'に', 'ホテル', 'が', '立って', 'る', 'んです', 'よー', '私', 'も', '今日', '\\u3000', '初めて', '行き', 'ました', '；', '；', 'レストラン', 'は', 'ビュッフェ', 'タイプ', 'でした', '\\u3000', '他', 'に', 'も', 'バー', 'と', 'か', 'あり', 'ました', 'よ', '？', '少々', 'お', '高い', 'です', 'が', '\\u3000', 'わりと', '楽しめ', 'ました', '！']\n",
      "Token IDs:  [1, 1409, 1120, 8416, 262, 6632, 457, 264, 1335, 267, 6008, 587, 602, 17697, 426, 276, 1464, 334, 964, 1459, 307, 377, 377, 3672, 266, 270, 11804, 1300, 3043, 1268, 588, 334, 477, 264, 276, 1624, 268, 294, 317, 307, 423, 354, 12233, 295, 672, 302, 267, 334, 28643, 7742, 307, 308, 2]\n"
     ]
    }
   ],
   "source": [
    "# モデルに飲ませるデータと、ラベルを準備\n",
    "text_test = df_test.text.values\n",
    "labels_test = df_test.label.values\n",
    "\n",
    "## 確認\n",
    "print(' Original: ', text_test[0])\n",
    "print('Tokenized: ', juman_tokenizer.tokenize(preprocessing_text(text_test[0])))\n",
    "print('Token IDs: ', tokenizer_with_preprocessing(text_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing:  え　 　ピューロランド　行き　たい　 　 　 　誰か　連れ　て　っ　て　←　絶対　ＳＫＹ　ー　ＨＩ　可愛い　やん　 　いや　 　カッコイイ　パターン　も　あり　？\n",
      "Preprocessing:  そういえば大阪のウンタラではＵＳＪのウンタラをウンタラするそうですねなるほどこの世界はなろう小説でしたか\n",
      "Preprocessing:  レゴランドの向いにホテルが立ってるんですよー私も今日 初めて行きました；；レストランはビュッフェタイプでした 他にもバーとかありましたよ？少々お高いですが わりと楽しめました！\n"
     ]
    }
   ],
   "source": [
    "text_train = preprocessing_sentences(text_train)\n",
    "text_val = preprocessing_sentences(text_val)\n",
    "text_test = preprocessing_sentences(text_test)\n",
    "print('Preprocessing: ', text_train[0])\n",
    "print('Preprocessing: ', text_val[0])\n",
    "print('Preprocessing: ', text_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  え　 　ピューロランド　行き　たい　 　 　 　誰か　連れ　て　っ　て　←　絶対　ＳＫＹ　ー　ＨＩ　可愛い　やん　 　いや　 　カッコイイ　パターン　も　あり　？\n",
      "Token IDs: tensor([    1,  2654, 31958,   334, 10681,   555,   702,  2459, 31958, 20476,\n",
      "        31958,  5981, 31958,   334,   334,   334,  6953,   644, 31958,  4018,\n",
      "          920, 31958,   359, 31958,  1138, 31958,   359, 31958, 26637, 31958,\n",
      "        21631, 31958,   800, 17490, 31958,   555, 31958, 14846, 31958, 29968,\n",
      "        31958,  1159,   956, 31958,   334,  7443, 31958,   334,   695,  7532,\n",
      "          895,   895, 31958,  1372, 17715, 31958,  1512, 31958, 14671, 31958,\n",
      "        11897,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids_train = []\n",
    "attention_masks_train = []\n",
    "max_len = 128\n",
    "\n",
    "# 1文づつ処理\n",
    "for sentence in text_train:\n",
    "    encoded_dict_train = tokenizer.encode_plus( # input_ids, token_type_ids, attention_mask を出力する\n",
    "                        sentence,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = max_len + 2,           # 文章の長さを固定（Padding/Trancatinating）\n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maskの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "\n",
    "    input_ids_train.append(encoded_dict_train['input_ids'])\n",
    "    attention_masks_train.append(encoded_dict_train['attention_mask']) # 実質的なトークンがある部分のみ１になる\n",
    "\n",
    "#input_ids_train.append(sentences_train['input_ids'])\n",
    "#attention_masks_train.append(sentences_train['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
    "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
    "\n",
    "# tensor型に変換\n",
    "labels_train = torch.tensor(labels_train)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', text_train[0])\n",
    "print('Token IDs:', input_ids_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  そういえば大阪のウンタラではＵＳＪのウンタラをウンタラするそうですねなるほどこの世界はなろう小説でしたか\n",
      "Token IDs: tensor([    1,   849,   457, 11628,  4092,   419,  8152, 16889,  5405,  6053,\n",
      "         1667,   419,  8152, 16889,  6731,  8152, 16889,  2648,  1416,   993,\n",
      "         2144, 28083,   362,  3260, 15511,  2402, 15735,  2975,   644,     2,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids_val = []\n",
    "attention_masks_val = []\n",
    "max_len = 128\n",
    "\n",
    "\n",
    "# 1文づつ処理\n",
    "for sentence in text_val:\n",
    "    encoded_dict_val = tokenizer.encode_plus( # input_ids, token_type_ids, attention_mask を出力する\n",
    "                        sentence,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = max_len + 2,           # 文章の長さを固定（Padding/Trancatinating）\n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maskの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "\n",
    "    input_ids_val.append(encoded_dict_val['input_ids'])\n",
    "    attention_masks_val.append(encoded_dict_val['attention_mask']) # 実質的なトークンがある部分のみ１になる\n",
    "\n",
    "#input_ids_train.append(sentences_train['input_ids'])\n",
    "#attention_masks_train.append(sentences_train['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
    "\n",
    "# tensor型に変換\n",
    "labels_val = torch.tensor(labels_val)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', text_val[0])\n",
    "print('Token IDs:', input_ids_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  レゴランドの向いにホテルが立ってるんですよー私も今日 初めて行きました；；レストランはビュッフェタイプでした 他にもバーとかありましたよ？少々お高いですが わりと楽しめました！\n",
      "Token IDs: tensor([    1,  1409,  1120,  2459,   419,  5285,   457,   370, 11826,  1202,\n",
      "        15045,   369,  1366,   677,  2472,   555,   771,  1512,  2283,   964,\n",
      "        20476,   645,  1260,  9278,  9278, 29829,  1428, 11804,  1300,  3043,\n",
      "        21581,  2975,   477, 11854,  1661,   515,   644, 14671,   645,  1260,\n",
      "         2472, 11897,  8868,  1113,   552, 15053,  7218, 28643,  2859,   494,\n",
      "         1077,   645,  1260, 10772,     2,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids_test = []\n",
    "attention_masks_test = []\n",
    "max_len = 128\n",
    "\n",
    "# 1文づつ処理\n",
    "for sentence in text_test:\n",
    "    encoded_dict_test = tokenizer.encode_plus( # input_ids, token_type_ids, attention_mask を出力する\n",
    "                        sentence,                      \n",
    "                        add_special_tokens = True, # Special Tokenの追加\n",
    "                        max_length = max_len + 2,           # 文章の長さを固定（Padding/Trancatinating）\n",
    "                        pad_to_max_length = True,# PADDINGで埋める\n",
    "                        return_attention_mask = True,   # Attention maskの作成\n",
    "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
    "                   )\n",
    "\n",
    "    input_ids_test.append(encoded_dict_test['input_ids'])\n",
    "    attention_masks_test.append(encoded_dict_test['attention_mask']) # 実質的なトークンがある部分のみ１になる\n",
    "\n",
    "#input_ids_train.append(sentences_train['input_ids'])\n",
    "#attention_masks_train.append(sentences_train['attention_mask'])\n",
    "\n",
    "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
    "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
    "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
    "\n",
    "# tensor型に変換\n",
    "labels_test = torch.tensor(labels_test)\n",
    "\n",
    "# 確認\n",
    "print('Original: ', text_test[0])\n",
    "print('Token IDs:', input_ids_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データローダーの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train) # input_ids_train, attention_masks_train, labels_train を使ってデータセットを作成\n",
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "\n",
    "# データローダーの作成\n",
    "batch_size = 16\n",
    "\n",
    "# datsets = [データセット全て]\n",
    "# Dataloader = [[batch_1], [batch_2], ... [batch_n]]\n",
    "\n",
    "# 訓練データローダー\n",
    "train_dataloader = DataLoader( # Dataloader : データセットからデータをバッチサイズに固めて返すモジュール\n",
    "    train_dataset,  \n",
    "    sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化（sampler : datasetsのバッチの固め方を決める事のできる設定）\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# 検証データローダー\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "# テストデータローダー\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    sampler = SequentialSampler(test_dataset), # 順番にデータを取得してバッチ化\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ku-nlp/deberta-v2-base-japanese were not used when initializing DebertaV2Model: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaV2Model\n",
    "\n",
    "class DebertaV2Classifier(nn.Module):\n",
    "  def __init__(self, model_name):\n",
    "    super(DebertaV2Classifier, self).__init__()\n",
    "    \n",
    "    # DeBERTa V2モデルをロード\n",
    "    self.deberta = DebertaV2Model.from_pretrained(model_name)\n",
    "    \n",
    "    # DeBERTaの隠れ層の次元数は768, カテゴリ数が2\n",
    "    self.linear = nn.Linear(768, 2)\n",
    "    \n",
    "    # 重み初期化処理\n",
    "    nn.init.normal_(self.linear.weight, std=0.02)\n",
    "    nn.init.normal_(self.linear.bias, 0)\n",
    "\n",
    "  def forward(self, input_ids):\n",
    "    # last_hidden_stateを受け取る\n",
    "    outputs = self.deberta(input_ids)\n",
    "    \n",
    "    # 先頭トークンclsのベクトルだけ取得\n",
    "    vec = outputs.last_hidden_state[:,0,:]\n",
    "    vec = vec.view(-1, 768)\n",
    "    \n",
    "    # 全結合層でクラス分類用に次元を変換\n",
    "    out = self.linear(vec)\n",
    "    \n",
    "    return out\n",
    "\n",
    "model_name = \"ku-nlp/deberta-v2-base-japanese\"\n",
    "model = DebertaV2Classifier(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファインチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakulab/anaconda3/envs/[yaguchi]/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ファインチューニング\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.deberta.encoder.layer[-1].named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name, param in model.linear.named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 最適化関数の設定\n",
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopping_path = '/home/sakulab/workspace/yaguchi/research/Master/code/LLM/Deberta/(ku-nlp)results/val5(epoch10)_chp'\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"earlystoppingクラス\"\"\"\n",
    "\n",
    "    def __init__(self, patience=10, verbose=False, path= EarlyStopping_path ):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience    #設定ストップカウンタ\n",
    "        self.verbose = verbose      #表示の有無\n",
    "        self.counter = 0            #現在のカウンタ値\n",
    "        self.best_score = None      #ベストスコア\n",
    "        self.early_stop = False     #ストップフラグ\n",
    "        self.val_loss_min = np.Inf   #前回のベストスコア記憶用\n",
    "        self.path = path             #ベストモデル格納path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        \"\"\"\n",
    "        特殊(call)メソッド\n",
    "        実際に学習ループ内で最小lossを更新したか否かを計算させる部分\n",
    "        \"\"\"\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:  #1Epoch目の処理\n",
    "            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する\n",
    "            self.checkpoint(val_loss, model)  #記録後にモデルを保存してスコア表示する\n",
    "        elif score < self.best_score:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1   #ストップカウンタを+1\n",
    "            if self.verbose:  #表示を有効にした場合は経過を表示\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する \n",
    "            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "        else:  #ベストスコアを更新した場合\n",
    "            self.best_score = score  #ベストスコアを上書き\n",
    "            self.checkpoint(val_loss, model)  #モデルを保存してスコア表示\n",
    "            self.counter = 0  #ストップカウンタリセット\n",
    "\n",
    "    def checkpoint(self, val_loss, model):\n",
    "        '''ベストスコア更新時に実行されるチェックポイント関数'''\n",
    "        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)  #ベストモデルを指定したpathに保存\n",
    "        self.val_loss_min = val_loss  #その時のlossを記録する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果の保存用\n",
    "history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc':[]\n",
    "    }\n",
    "\n",
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    #★EarlyStoppingクラスのインスタンス化とエアearylistoppingの設定\n",
    "    earlystopping = EarlyStopping(patience=10)\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    \n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    model.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # ミニバッチのサイズ\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # モデルを訓練モードに\n",
    "               \n",
    "            else:\n",
    "                model.eval()   # モデルを検証モードに\n",
    "\n",
    "            epoch_loss = 0.0  # epochの損失和\n",
    "            epoch_corrects = 0  # epochの正解数\n",
    "            iteration = 1\n",
    "\n",
    "            # 開始時刻を保存\n",
    "            t_epoch_start = time.time()\n",
    "            t_iter_start = time.time()\n",
    "\n",
    "            # データローダーからミニバッチを取り出すループ\n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                # batchはTextとLableの辞書型変数\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                #inputs = batch.Text[0].to(device)  # 文章 input_ids\n",
    "                inputs = batch[0].to(device)  # 文章 input_ids\n",
    "                #labels = batch.Label.to(device)  # ラベル\n",
    "                labels = batch[2].to(device)  # ラベル\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # Bertに入力\n",
    "                    outputs= model(inputs)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)  # 損失を計算\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                       \n",
    "                      \n",
    "                    # 損失と正解数の合計を更新\n",
    "                    epoch_loss += loss.item() * batch_size\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "      \n",
    "            # epochごとのlossと正解率\n",
    "            t_epoch_finish = time.time()\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double(\n",
    "            ) / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
    "                                                                           phase, epoch_loss, epoch_acc))\n",
    "            t_epoch_start = time.time()\n",
    "\n",
    "            \n",
    "            if phase == 'train':\n",
    "                 history['train_loss'].append(epoch_loss)\n",
    "                 history['train_acc'].append(epoch_acc)\n",
    "            else:\n",
    "                history['val_loss'].append(epoch_loss)   \n",
    "                history['val_acc'].append(epoch_acc)\n",
    "                \n",
    "        earlystopping(epoch_loss, model) #callメソッド呼び出し\n",
    "        if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "              print(\"Early Stopping!\")\n",
    "              break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "Epoch 1/10 | train |  Loss: 0.5150 Acc: 0.7553\n",
      "Epoch 1/10 |  val  |  Loss: 0.5189 Acc: 0.7239\n",
      "Epoch 2/10 | train |  Loss: 0.4987 Acc: 0.7577\n",
      "Epoch 2/10 |  val  |  Loss: 0.5108 Acc: 0.7540\n",
      "Epoch 3/10 | train |  Loss: 0.4896 Acc: 0.7591\n",
      "Epoch 3/10 |  val  |  Loss: 0.5244 Acc: 0.7199\n",
      "Epoch 4/10 | train |  Loss: 0.4840 Acc: 0.7624\n",
      "Epoch 4/10 |  val  |  Loss: 0.5069 Acc: 0.7470\n",
      "Epoch 5/10 | train |  Loss: 0.4768 Acc: 0.7666\n",
      "Epoch 5/10 |  val  |  Loss: 0.4997 Acc: 0.7520\n",
      "Epoch 6/10 | train |  Loss: 0.4740 Acc: 0.7680\n",
      "Epoch 6/10 |  val  |  Loss: 0.5066 Acc: 0.7359\n",
      "Epoch 7/10 | train |  Loss: 0.4666 Acc: 0.7731\n",
      "Epoch 7/10 |  val  |  Loss: 0.5024 Acc: 0.7530\n",
      "Epoch 8/10 | train |  Loss: 0.4629 Acc: 0.7743\n",
      "Epoch 8/10 |  val  |  Loss: 0.4980 Acc: 0.7550\n",
      "Epoch 9/10 | train |  Loss: 0.4524 Acc: 0.7844\n",
      "Epoch 9/10 |  val  |  Loss: 0.4963 Acc: 0.7480\n",
      "Epoch 10/10 | train |  Loss: 0.4410 Acc: 0.7893\n",
      "Epoch 10/10 |  val  |  Loss: 0.4996 Acc: 0.7560\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": validation_dataloader}\n",
    "model_trained = train_model(model, dataloaders_dict,\n",
    "                          criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベストモデルを適応させる\n",
    "model_trained.load_state_dict(torch.load(EarlyStopping_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正解率の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:05<00:00, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ1998個での正解率：0.7693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# テストデータでの正解率を求める\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_trained.eval()   # モデルを検証モードに\n",
    "model_trained.to(device)  # GPUが使えるならGPUへ送る\n",
    "\n",
    "# epochの正解数を記録する変数\n",
    "epoch_corrects = 0\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for batch in tqdm(test_dataloader):  # testデータのDataLoader\n",
    "    # batchはTextとLableの辞書オブジェクト\n",
    "    # GPUが使えるならGPUにデータを送る\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #inputs = batch.Text[0].to(device)  # 文章\n",
    "    inputs = batch[0].to(device)  # 文章\n",
    "    #labels = batch.Label.to(device)  # ラベル\n",
    "    labels = batch[2].to(device)  # ラベル\n",
    "\n",
    "    # 順伝搬（forward）計算\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "       \n",
    "        outputs = model_trained(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)  # 損失を計算\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "\n",
    "        if y_pred == []:\n",
    "          y_pred = preds\n",
    "        else:\n",
    "          y_pred = torch.cat([y_pred, preds], dim=0)\n",
    "        \n",
    "        epoch_corrects += torch.sum(preds == labels.data)  # 正解数の合計を更新\n",
    "\n",
    "# 正解率\n",
    "epoch_acc = epoch_corrects.double() / len(test_dataloader.dataset)\n",
    "\n",
    "print('テストデータ{}個での正解率：{:.4f}'.format(len(test_dataloader.dataset), epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分類評価指標4つでの結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7693\n",
      "precision = 0.5566\n",
      "recall = 0.2433\n",
      "f1 score = 0.3386\n"
     ]
    }
   ],
   "source": [
    "# 評価指標の算出\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 評価指標算出メソッドの作成\n",
    "def print_metrics_by_cutoff(y, y_pred, model, cutoff):\n",
    "    \"\"\"\n",
    "    指定した閾値に基づくAccuracy, Precision, Recall, F1-scoreを出力する\n",
    "    \"\"\"\n",
    "    #y_pred = model.predict_proba(X)[:, 1] >= cutoff\n",
    "    print('accuracy = {:.4f}'.format(accuracy_score(y_true=y, y_pred=y_pred)))\n",
    "    print('precision = {:.4f}'.format(precision_score(y_true=y, y_pred=y_pred)))\n",
    "    print('recall = {:.4f}'.format(recall_score(y_true=y, y_pred=y_pred)))\n",
    "    print('f1 score = {:.4f}'.format(f1_score(y_true=y, y_pred=y_pred)))\n",
    "    # Accuracy, Precision, Recall, F1-score\n",
    "print_metrics_by_cutoff(y=labels_test, y_pred=y_pred, model=model_trained, cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPUのメモリ解放\n",
    "! kill -9 $(lsof -t /dev/nvidia*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Mon Jul 31 12:44:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:81:00.0  On |                  N/A |\n",
      "| 42%   43C    P8    38W / 350W |   2411MiB / 24576MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 30%   42C    P8    27W / 350W |     13MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2157250      G   /usr/lib/xorg/Xorg                 53MiB |\n",
      "|    0   N/A  N/A   2815414      G   /usr/lib/xorg/Xorg                150MiB |\n",
      "|    0   N/A  N/A   2987369      G   /usr/bin/gnome-shell               84MiB |\n",
      "|    0   N/A  N/A   2992243      C   ...envs/[yaguchi]/bin/python     2103MiB |\n",
      "|    1   N/A  N/A   2157250      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   2815414      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[yaguchi]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
